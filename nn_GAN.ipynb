{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12170,"status":"ok","timestamp":1713806264253,"user":{"displayName":"alessandro rossomando","userId":"08514102832469229209"},"user_tz":-120},"id":"LSKCiWoix9df","outputId":"80420927-e977-4279-b1cd-ec6ec969b19c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Success\n"]}],"source":["import torch #importa libreria PyTorch per l'elaborazione del tensore\n","import torch.nn as nn # importa modulo nn , contiene le funzioni e le classi per la definizione di reti neurali\n","\n","class Discriminator(nn.Module): # classe che eredita dalla classe nn.Module\n","    def __init__(self, channels_img, features_d):# metodo che  inizializza il discriminatore, con due parametri in ingresso: rispettivamente il numero di canali dell'immagine e il numero di features maps\n","        super(Discriminator,self).__init__()# chiama il costruttore della classe padre\n","        self.disc = nn.Sequential(\n","            # definisce una sequenza di strati neurali 'conteiner'\n","            # IN : N x channels_img x 64 x 64\n","            nn.Conv2d(\n","\n","               # primo strato convoluzionale.\n","                #Prendi in ingresso immagini con il numero specificato da channels-img e rstituisce features map.\n","                #il filtro è 4x4, lo stride è 2 => l'output sarà di una dimensione minore.\n","                #padding= 1 (aggunge zeri intorno all'immagine di input)\n","\n","                channels_img, features_d, kernel_size = 4, stride= 2, padding= 1\n","            ),# 32x32\n","            nn.LeakyReLU(0.5),\n","\n","            # funzione di attivazione non lineare applicata alle feature map dello strato precedente.\n","             #La costante 0.5 specifica il coefficiente di pendanza per i valori negativi\n","\n","            self._blok(features_d,features_d*2,4,2,1),# 16 x 16\n","            self._blok(features_d * 2, features_d * 4, 4, 2, 1),#8 x 8\n","            self._blok(features_d * 4, features_d * 8, 4, 2, 1),# 4 x 4\n","            nn.Conv2d(features_d * 8, 1, kernel_size=4,stride=2, padding=0),# restituisce un singolo valore in out\n","            nn.Sigmoid(),\n","\n","             #funzione di attivazione per produrre un valore compreso tra 0 e 1,\n","             #rappresenta la probabilità che l'input sia un immagine reale(1)o immagine generata(0)\n","\n","        )\n","        #metodo privato blok per creare strati del nostro modello\n","    def _blok(self, in_channels, out_channels,kernel_size, stride, padding):\n","\n","      #Definisce un blocco di convoluzione con normalizzazione batch e LeakyReLU.\n","      #Prende come argomenti il numero di canali in ingresso,\n","      #il numero di canali in uscita, le dimensioni del kernel,\n","      #lo stride e il padding.\n","\n","        return nn.Sequential( # restutuisce una sequenza di strati\n","            nn.Conv2d(\n","                in_channels,\n","                out_channels,\n","                kernel_size,\n","                stride,\n","                padding,\n","                bias = False,\n","            ),\n","            nn.BatchNorm2d(out_channels),\n","            nn.LeakyReLU(0.2),# segue implementazione paper\n","        )\n","    def forward(self, x): # definisce come i dati vengono propagati attraverso il discriminatore\n","        return self.disc(x) # input passa attraverso il corpo prinzipale del discriminatore\n","\n","\n","class Generator(nn.Module):# eredita da nn.Module per crare il generatore\n","    def __init__(self, z_dim, channels_img, features_g):\n","\n","    #inizializza il generatore con: dimensione dello spazio latente,\n","    #numero canali dell'immagine in output e il numero di feature maps desiderate\n","\n","        super(Generator,self).__init__()# chiama il metodo di nìinizializzazione della calssa genitor, per inizializzare correttamente la classe generetor\n","        self.gen = nn.Sequential( # definisce il generatore con i diversi strati, corpo principale del modello\n","            #IN: N x z_dim x 1 x 1\n","            self._blok( z_dim, features_g * 16,4,1,0),#N x f_g*16 x 4 x 4\n","            self._blok(features_g * 16, features_g * 8, 4, 2, 1),# 8x8\n","            self._blok(features_g * 8, features_g * 4, 4, 2, 1),#16x16\n","            self._blok(features_g * 4, features_g * 2, 4, 2, 1),#32x32\n","            nn.ConvTranspose2d(features_g * 2, channels_img, kernel_size=4, stride=2, padding=1),\n","\n","            #prende le feature map dallo strato precedente\n","            #e produce un'immagine con il numero di canali specificato da ' channels-img'\n","\n","            nn.Tanh(), #funzione di attivazione per garantire che i valori siano compresi nell'intervallo [-1, 1]\n","        )\n","    def _blok(self, in_channels, out_channels,kernel_size, stride, padding):\n","\n","      #metodo definisce un blocco di convoluzione trasposta con normalizzazione batch e ReLU.\n","      #Prende come argomenti il numero di canali in ingresso,\n","      #il numero di canali in uscita, le dimensioni del kernel,\n","      #lo stride e il padding.\n","\n","        return nn.Sequential(\n","            nn.ConvTranspose2d(\n","                in_channels,\n","                out_channels,\n","                kernel_size,\n","                stride,\n","                padding,\n","                bias = False,\n","            ),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","        )\n","    def forward(self, x): # come vengono propagati i dati attraverso il generatore\n","        return self.gen(x)\n","\n","def initialize_weights(model):# inizializzazione dei pesi dei modelli\n","\n","#prende come input un modello di rete neurale (model).\n","#Itera attraverso tutti i moduli del modello (model.modules()) e,\n","#se il modulo è un'istanza di nn.Conv2d, nn.ConvTranspose2d, o nn.BatchNorm2d,\n","#inizializza i pesi di quel modulo con una distribuzione normale con media 0.0 e deviazione standard 0.02.\n","\n","    for n in model.modules():\n","        if isinstance(n, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n","            nn.init.normal_(n.weight.data, 0.0, 0.02)\n","\n","def test():# definisce una serie di test\n","    N, in_channels, H, W = 8, 3, 64, 64\n","    z_dim = 100\n","    x = torch.randn(N, in_channels, H, W)# batch di dati casuali\n","    disc = Discriminator(in_channels, 8)# istanziato modello\n","    initialize_weights(disc)\n","    assert disc(x).shape == (N,1,1,1)# contollo per verificare se le dimensioni delle uscite sono corrette\n","    gen = Generator(z_dim, in_channels, 8)\n","    initialize_weights(gen)\n","    z = torch.randn((N, z_dim, 1, 1))\n","    assert gen(z).shape == (N, in_channels, H, W)\n","    print('Success')\n","\n","test()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"executionInfo":{"elapsed":10,"status":"error","timestamp":1713806264253,"user":{"displayName":"alessandro rossomando","userId":"08514102832469229209"},"user_tz":-120},"id":"RxfrEUGL9R1k","outputId":"18f47c23-6759-4798-8e37-6509c1664fde"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/Alessandro Rossomando/img_align_celeba.zip'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-73929ad6c84d>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m# estrae il contenuto dle file ZIP (zip_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# estrae tutto il contenuto per inserirlo nella destinazione specificata(extract_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Alessandro Rossomando/img_align_celeba.zip'"]}],"source":["import zipfile # modulo per lavorare con dile ZIP\n","import os # modulo per lavorare xon operazioni di sistema operativo\n","\n","# Percorso del file ZIP sul Google Drive\n","zip_path = \"/content/drive/MyDrive/Alessandro Rossomando/img_align_celeba.zip\"\n","\n","# Percorso di destinazione per l'estrazione\n","extract_path = \"/content/img_align_celeba\"\n","\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:# estrae il contenuto dle file ZIP (zip_path)\n","    zip_ref.extractall(extract_path) # estrae tutto il contenuto per inserirlo nella destinazione specificata(extract_path)\n","\n","# Verifica l'estrazione : restituisce una lista dei file e delle cartelle presenti nella cartella estratta\n","os.listdir(extract_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KePlG1rKyNnL"},"outputs":[],"source":["import torch #mpdulo PyTorch per funzionalità di base\n","import torch.nn as nn # per definire le reti neurali\n","import torch.optim as optim # per  gli ottimizzatori\n","import torchvision # getire dei dataset di immagini\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader, SubsetRandomSampler\n","import matplotlib.pyplot as plt # visualizzazione delle immgini\n","import matplotlib.image as mpimg # per il caricamento delle immagini\n","genlosses = []\n","dislosses = []\n","\n","# Parametri\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # dispositivo di esecuzione\n","IMAGE_SIZE = 64\n","CHANNELS_IMG = 3\n","\n","# Definizione delle trasformazioni\n","transforms = transforms.Compose([\n","\n","    #definisce le trasformazioni da applicare alle immagini prima di passarle al modello\n","    #le immagini vengono ridimensionate,convertite in tensori e normalizzate\n","\n","    transforms.Resize(IMAGE_SIZE),\n","    #transforms.CenterCrop(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        [0.5 for _ in range(CHANNELS_IMG)] ,[0.5 for _ in range(CHANNELS_IMG)]),\n","])\n","#carico il dataset dal percorso specificato e applica le trasformazioni\n","dataset_full = datasets.ImageFolder(root=\"img_align_celeba\",transform = transforms )\n","num_img = 3500\n","\n","subset_idx = list(range(num_img))\n","subset_sampler = SubsetRandomSampler(subset_idx)# creo un campione casuale di immagini dal dataset\n","dataset_subset = torch.utils.data.Subset(dataset_full, subset_idx)\n","\n","# Def diverse combinazioni di iperparametri da provare\n","hyperparameters = [\n","   # {\"L_R\": 0.0001, \"BATCH_SIZE\": 64, \"Z_DIM\": 64, \"NUM_EPOCHS\": 10, \"FEATURES_DISC\": 32, \"FEATURES_GEN\": 32},\n","    {\"L_R\": 0.0001, \"BATCH_SIZE\": 64, \"Z_DIM\": 64, \"NUM_EPOCHS\": 3, \"FEATURES_DISC\": 32, \"FEATURES_GEN\": 32},\n","   # {\"L_R\": 0.0005, \"BATCH_SIZE\": 64, \"Z_DIM\": 64, \"NUM_EPOCHS\": 10, \"FEATURES_DISC\": 32, \"FEATURES_GEN\": 32},\n","    #{\"L_R\": 0.0005, \"BATCH_SIZE\": 64, \"Z_DIM\": 64, \"NUM_EPOCHS\": 30, \"FEATURES_DISC\": 32, \"FEATURES_GEN\": 32},\n","    #{\"L_R\": 0.0001, \"BATCH_SIZE\": 128, \"Z_DIM\": 64, \"NUM_EPOCHS\": 10, \"FEATURES_DISC\": 32, \"FEATURES_GEN\": 32},\n","    #{\"L_R\": 0.0001, \"BATCH_SIZE\": 128, \"Z_DIM\": 64, \"NUM_EPOCHS\": 30, \"FEATURES_DISC\": 32, \"FEATURES_GEN\": 32},\n","    #{\"L_R\": 0.0005, \"BATCH_SIZE\": 128, \"Z_DIM\": 64, \"NUM_EPOCHS\": 10, \"FEATURES_DISC\": 32, \"FEATURES_GEN\": 32},\n","    #{\"L_R\": 0.0005, \"BATCH_SIZE\": 128, \"Z_DIM\": 64, \"NUM_EPOCHS\": 30, \"FEATURES_DISC\": 32, \"FEATURES_GEN\": 32},\n","\n","     #{\"L_R\": 0.0002, \"BATCH_SIZE\": 128, \"Z_DIM\": 128, \"NUM_EPOCHS\": 100, \"FEATURES_DISC\": 64, \"FEATURES_GEN\": 64},\n","    # Aggiungi altre combinazioni di iperparametri che desideri provare\n","]\n","\n","for idx, params in enumerate(hyperparameters):\n","     # Estrai i parametri dalla configurazione corrente\n","     L_R = params[\"L_R\"]\n","     BATCH_SIZE = params[\"BATCH_SIZE\"]\n","     Z_DIM = params[\"Z_DIM\"]\n","     NUM_EPOCHS = params[\"NUM_EPOCHS\"]\n","     FEATURES_DISC = params[\"FEATURES_DISC\"]\n","     FEATURES_GEN = params[\"FEATURES_GEN\"]\n","\n","\n","     loader = DataLoader ( dataset_subset ,batch_size= BATCH_SIZE ,shuffle=True)# DataLoader per caricare i dati in batch durante l'addestramento del modello\n","     gen = Generator(Z_DIM,CHANNELS_IMG,FEATURES_GEN,).to(device)# inizializza generatore e li sposta sul dispositivo specificato\n","     disc = Discriminator(CHANNELS_IMG,FEATURES_DISC).to(device)# inizializza discriminatore\n","     initialize_weights(gen)# inizializza pesi del modello\n","     initialize_weights(disc)\n","\n","    #definisco gli ottimizzatori e la funzione di loss\n","     opt_gen = optim.NAdam(gen.parameters(),lr = L_R, betas=(0.5,0.999))\n","     opt_disc = optim.NAdam(disc.parameters(),lr = L_R, betas=(0.5,0.999))\n","     criterion = nn.BCELoss() # Binary Cross Entropy Loss\n","\n","     fixed_noise= torch.randn(32,Z_DIM,1,1).to(device) # tensore di rumore fisso per generare immagini durante il training\n","     step = 0\n","\n","    # imposto i modelli in modalità di addestramento\n","     gen.train()\n","     disc.train()\n","\n","    #ciclo principale di addestramento\n","    #scorre le epoche e le iterazioni all'interno di ciascuna epoca, ottenendo i dati dal 'DataLoader'\n","     for epoch in range(NUM_EPOCHS):\n","         for batch_idx, (real, _) in enumerate(loader):\n","\n","             real = real.to(device)# vengono spostati i dati sul dispositivo\n","             noise = torch.randn((BATCH_SIZE, Z_DIM,1,1)).to(device)# generato il rumore per le immagini finte\n","             fake = gen(noise)# generata un'immagine finta utilizzando il modello\n","\n","            ### Train Discriminator max log(D(x)) + log(1- D(G(z)))\n","             disc_real= disc(real).reshape(-1)\n","             loss_disc_real=criterion(disc_real, torch.ones_like(disc_real))\n","             disc_fake = disc(fake).reshape(-1)\n","             loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n","             loss_disc = (loss_disc_real + loss_disc_fake)/ 2\n","             disc.zero_grad()\n","             torch.cuda.empty_cache()\n","             dislosses.append(loss_disc)\n","             loss_disc.backward(retain_graph = True)\n","             opt_disc.step()\n","          # torch.cuda.empty_cache()\n","\n","            ### Train Generator min log(1-D(g(z))) === max log(D(G(z))\n","             output = disc(fake).reshape(-1)\n","             loss_gen = criterion(output, torch.ones_like(output))\n","             genlosses.append(loss_gen)\n","             gen.zero_grad()\n","             loss_gen.backward()\n","             opt_gen.step()\n","\n","            #torch.cuda.empty_cache()\n","\n","            # Print losses occasionally and print\n","             if batch_idx % 30 == 0:\n","\n","              #ogni 50 iterazioni viene stampato il valore della loss per entambi i modelli\n","                 print(\n","                     f\"[Epoch {epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(loader)} \\\n","                       D Loss: {loss_disc:.6f}, G Loss: {loss_gen:.6f}\"\n","                 )\n","                 with torch.no_grad():\n","                     fake = gen(fixed_noise)\n","\n","\n","                    # Visualizza un campione di immagini generate\n","                     fig, axes = plt.subplots(3, 3, figsize=(5, 5))\n","                     for i, ax in enumerate(axes.flatten()):\n","                         img_normalized = (fake[i].cpu().permute(1, 2, 0).numpy() + 1) / 2\n","                         ax.imshow(img_normalized)\n","                         ax.axis('off')\n","                     plt.show()\n","                 step += 1\n","                 print(f\"Configurazione {idx+1}: Loss generatore = {loss_gen:.6f},   D Loss: {loss_disc:.6f}\")\n","\n","\n","\n"]},{"cell_type":"code","source":["ge = loss_gen.clone().detach().cpu().long()\n","de = loss_disc.clone().detach().cpu().long()\n","\n","\n","\n","plt.figure(figsize=(10,5))\n","plt.title(\"Generator and Discriminator Loss During Training\")\n","plt.plot(ge,label=\"G\")\n","plt.plot(de,label=\"D\")\n","plt.xlabel(\"iterations\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"MeXxtPIJrZcb"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}